# üìö GUIA COMPLETO: RAG Document Extractor

## üéØ **COMO USAR PARA QUALQUER ARQUIVO**

### 1Ô∏è‚É£ **Setup Inicial (Uma vez s√≥)**

```bash
# Instalar depend√™ncias
pip install pdfplumber pathlib

# Copiar o arquivo rag_extractor_corrected.py para sua pasta
# Colocar seus PDFs na mesma pasta do script
```

### 2Ô∏è‚É£ **Extrair Qualquer PDF**

```python
# M√©todo 1: Direto no script
python rag_extractor_corrected.py

# M√©todo 2: Personalizado
from rag_extractor_corrected import CompletePDFExtractor

# Inicializar
extractor = CompletePDFExtractor(output_dir="./meus_outputs")

# Processar arquivo
results = extractor.process_pdf("meu_arquivo.pdf")
```

### 3Ô∏è‚É£ **Personalizar para Diferentes Tipos**

```python
# Para diferentes tipos de documento, modifique as fun√ß√µes:

def extract_complete_table_from_text(self, text: str, page_num: int):
    # Adicionar padr√µes espec√≠ficos do seu documento
    if "Meu padr√£o espec√≠fico" in text:
        # L√≥gica personalizada
        pass

def is_title(self, line: str):
    # Adicionar indicadores de t√≠tulo do seu tipo de documento
    my_indicators = ["Cap√≠tulo", "Se√ß√£o", "Anexo"]
    return any(indicator in line for indicator in my_indicators)
```

---

## ü§ñ **COMO USAR COM IA (AGENTES)**

### üìä **Formatos Dispon√≠veis**

Ap√≥s extra√ß√£o, voc√™ ter√° 4 arquivos:

```
rag_outputs/
‚îú‚îÄ‚îÄ markdown/     # Para leitura humana
‚îú‚îÄ‚îÄ json/         # Para dados estruturados  
‚îú‚îÄ‚îÄ chunks/       # Para alimentar IA
‚îî‚îÄ‚îÄ metadata/     # Para estat√≠sticas
```

### üß© **Chunks para IA (RECOMENDADO)**

```python
import json

# Carregar chunks otimizados para IA
with open('rag_outputs/chunks/arquivo_chunks.json', 'r', encoding='utf-8') as f:
    chunks = json.load(f)

# Cada chunk tem:
for chunk in chunks:
    print(f"ID: {chunk['chunk_id']}")
    print(f"Tipo: {chunk['type']}")        # 'text' ou 'table'
    print(f"P√°gina: {chunk['page']}")
    print(f"Conte√∫do: {chunk['content']}")  # Texto otimizado para IA
    
    if chunk['type'] == 'table':
        print(f"Tabela raw: {chunk['raw_table']}")  # Dados da tabela
```

### üöÄ **Integra√ß√£o com Agentes IA**

#### **OpenAI/ChatGPT:**
```python
import openai

# Carregar chunks
chunks_content = ""
for chunk in chunks:
    chunks_content += f"\\n\\n[{chunk['type'].upper()} - P√°gina {chunk['page']}]\\n"
    chunks_content += chunk['content']

# Enviar para IA
response = openai.chat.completions.create(
    model="gpt-4",
    messages=[
        {"role": "system", "content": "Voc√™ √© um assistente especializado em an√°lise de documentos."},
        {"role": "user", "content": f"Analise este documento:\\n{chunks_content}\\n\\nPergunta: [SUA PERGUNTA]"}
    ]
)
```

#### **Anthropic Claude:**
```python
import anthropic

client = anthropic.Anthropic(api_key="sua_key")

# Preparar contexto
context = "\\n\\n".join([
    f"[{chunk['type'].upper()} - P√°gina {chunk['page']}] {chunk['content']}" 
    for chunk in chunks
])

message = client.messages.create(
    model="claude-3-5-sonnet-20241022",
    max_tokens=4000,
    messages=[
        {"role": "user", "content": f"Contexto: {context}\\n\\nPergunta: [SUA PERGUNTA]"}
    ]
)
```

#### **Agentes Locais (Ollama, LM Studio):**
```python
import requests

# Para Ollama
def query_ollama(chunks, question):
    context = "\\n".join([chunk['content'] for chunk in chunks])
    
    response = requests.post('http://localhost:11434/api/generate', 
        json={
            'model': 'llama2',
            'prompt': f"Contexto: {context}\\n\\nPergunta: {question}",
            'stream': False
        })
    
    return response.json()['response']
```

### üìã **Estrat√©gias de Uso Eficiente**

#### **1. Busca Sem√¢ntica**
```python
# Filtrar chunks relevantes antes de enviar para IA
def find_relevant_chunks(chunks, keywords):
    relevant = []
    for chunk in chunks:
        if any(keyword.lower() in chunk['content'].lower() for keyword in keywords):
            relevant.append(chunk)
    return relevant

# Exemplo
autocad_chunks = find_relevant_chunks(chunks, ["AutoCAD", "Architecture", "productivity"])
```

#### **2. An√°lise por Tipo**
```python
# Separar texto de tabelas
text_chunks = [c for c in chunks if c['type'] == 'text']
table_chunks = [c for c in chunks if c['type'] == 'table']

# Perguntas diferentes para cada tipo
text_analysis = query_ai(text_chunks, "Resuma os principais pontos deste documento")
table_analysis = query_ai(table_chunks, "Analise os dados num√©ricos e crie insights")
```

#### **3. An√°lise Progressiva**
```python
# Quebrar em partes para evitar limite de tokens
def analyze_in_batches(chunks, batch_size=5):
    results = []
    for i in range(0, len(chunks), batch_size):
        batch = chunks[i:i+batch_size]
        result = query_ai(batch, "Analise esta se√ß√£o")
        results.append(result)
    return results
```

---

## ‚ö° **EXEMPLOS PR√ÅTICOS**

### üìä **An√°lise de Dados (Como AutoCAD)**
```python
# Extrair todas as tabelas
tables = [chunk for chunk in chunks if chunk['type'] == 'table']

# Analisar produtividade
productivity_question = """
Baseado nas tabelas extra√≠das:
1. Qual tarefa tem maior economia de tempo?
2. Qual a m√©dia de economia geral?
3. Que insights podemos extrair?
"""

response = query_ai(tables, productivity_question)
```

### üìñ **Resumo Executivo**
```python
# Pegar apenas texto das primeiras p√°ginas
intro_chunks = [c for c in chunks if c['page'] <= 5 and c['type'] == 'text']

summary = query_ai(intro_chunks, "Crie um resumo executivo de 200 palavras")
```

### üîç **Busca Espec√≠fica**
```python
def search_document(chunks, query):
    relevant_chunks = find_relevant_chunks(chunks, query.split())
    
    if relevant_chunks:
        context = "\\n\\n".join([c['content'] for c in relevant_chunks])
        return query_ai([{'content': context}], f"Responda: {query}")
    else:
        return "Informa√ß√£o n√£o encontrada no documento"

# Exemplo
answer = search_document(chunks, "Como criar eleva√ß√µes no AutoCAD?")
```

---

## üéØ **DICAS DE OTIMIZA√á√ÉO**

### 1. **Limite de Tokens**
- Monitore o tamanho dos chunks
- Use `char_count` e `word_count` para controlar envio
- Divida documentos grandes em batches

### 2. **Qualidade dos Prompts**
- Seja espec√≠fico sobre o tipo de an√°lise
- Inclua contexto sobre o tipo de documento
- Pe√ßa formatos espec√≠ficos de resposta

### 3. **Cache de Resultados**
```python
import pickle

# Salvar chunks processados
with open('chunks_cache.pkl', 'wb') as f:
    pickle.dump(chunks, f)

# Carregar rapidamente
with open('chunks_cache.pkl', 'rb') as f:
    chunks = pickle.load(f)
```

### 4. **Valida√ß√£o de Extra√ß√£o**
```python
# Verificar qualidade da extra√ß√£o
def validate_extraction(results):
    print(f"‚úÖ P√°ginas: {results['pages_processed']}/{results['total_pages']}")
    print(f"‚úÖ Tabelas: {results['tables_found']}")
    
    if results['pages_processed'] < results['total_pages']:
        print("‚ö†Ô∏è  Algumas p√°ginas n√£o foram processadas")
    
    if results['tables_found'] == 0:
        print("‚ö†Ô∏è  Nenhuma tabela encontrada - verificar documento")
```

---

## üîß **TROUBLESHOOTING**

### ‚ùå **Problemas Comuns**

1. **Tabelas n√£o extra√≠das:**
   - Verificar se tabelas est√£o em formato texto (n√£o imagem)
   - Ajustar regex patterns na fun√ß√£o `parse_table_row()`

2. **P√°ginas vazias:**
   - PDF pode ter p√°ginas s√≥ com imagens
   - Usar OCR se necess√°rio: `pip install pytesseract`

3. **Encoding errors:**
   - Sempre usar `encoding='utf-8'`
   - Verificar caracteres especiais

4. **Mem√≥ria insuficiente:**
   - Processar PDFs grandes em lotes
   - Usar `pdfplumber` com configura√ß√µes otimizadas

### üõ†Ô∏è **Customiza√ß√µes Avan√ßadas**

```python
# Para documentos espec√≠ficos, sobrescrever m√©todos:
class CustomExtractor(CompletePDFExtractor):
    def extract_complete_table_from_text(self, text, page_num):
        # L√≥gica personalizada para seu tipo de documento
        return super().extract_complete_table_from_text(text, page_num)
    
    def is_title(self, line):
        # Padr√µes espec√≠ficos do seu documento
        return "MEU_PADR√ÉO" in line
```

---

## üéâ **RESULTADO FINAL**

Com este sistema voc√™ pode:

‚úÖ **Extrair qualquer PDF** com precis√£o  
‚úÖ **Alimentar qualquer IA** com dados estruturados  
‚úÖ **Automatizar an√°lises** de documentos  
‚úÖ **Criar agentes especializados** em seus documentos  
‚úÖ **Escalar para milhares** de arquivos  

**O sistema RAG Local-First est√° pronto para produ√ß√£o! üöÄ**
