#!/usr/bin/env python3
"""
üé¨ EXTRATOR RAG COMPLETO - YOUTUBE
=================================
Sistema completo para extra√ß√£o de v√≠deos do YouTube com funcionalidade RAG completa baseado no sistema antigo funcionando.
Inclui todas as funcionalidades: analysis, summary, text, transcript, database, chunks, filtro de keywords, organiza√ß√£o avan√ßada.
"""

import os
import sys
import json
import csv
import sqlite3
import shutil
import zipfile
import argparse
import re
import logging
import time
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from urllib.parse import urlparse, parse_qs
from collections import Counter

# Imports para YouTube
try:
    import yt_dlp
    YT_DLP_AVAILABLE = True
except ImportError:
    print("‚ùå yt-dlp n√£o instalado. Execute: pip install yt-dlp")
    YT_DLP_AVAILABLE = False

try:
    from youtube_transcript_api import YouTubeTranscriptApi
    from youtube_transcript_api.formatters import TextFormatter
    YOUTUBE_TRANSCRIPT_AVAILABLE = True
except ImportError:
    print("‚ùå youtube-transcript-api n√£o instalado. Execute: pip install youtube-transcript-api")
    YOUTUBE_TRANSCRIPT_AVAILABLE = False

# Tentar importar bibliotecas para transcri√ß√£o local
try:
    import whisper
    WHISPER_AVAILABLE = True
    print("‚úÖ Whisper dispon√≠vel para transcri√ß√£o local")
except ImportError:
    WHISPER_AVAILABLE = False

try:
    import speech_recognition as sr
    SPEECH_RECOGNITION_AVAILABLE = True
    print("‚úÖ SpeechRecognition dispon√≠vel")
except ImportError:
    SPEECH_RECOGNITION_AVAILABLE = False

try:
    from pydub import AudioSegment
    PYDUB_AVAILABLE = True
except ImportError:
    PYDUB_AVAILABLE = False

try:
    import requests
    from bs4 import BeautifulSoup
    WEB_SCRAPING_AVAILABLE = True
except ImportError:
    print("‚ùå requests/beautifulsoup4 n√£o instalados. Execute: pip install requests beautifulsoup4")
    WEB_SCRAPING_AVAILABLE = False

try:
    import pandas as pd
    PANDAS_AVAILABLE = True
except ImportError:
    print("‚ùå pandas n√£o instalado. Execute: pip install pandas")
    PANDAS_AVAILABLE = False

# Configura√ß√£o de logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Stop words para filtro de keywords
STOP_WORDS = {
    'en': {
        'the', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 
        'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 
        'do', 'does', 'did', 'will', 'would', 'could', 'should', 'may', 'might',
        'a', 'an', 'this', 'that', 'these', 'those', 'i', 'you', 'he', 'she', 
        'it', 'we', 'they', 'me', 'him', 'her', 'us', 'them', 'my', 'your', 
        'his', 'her', 'its', 'our', 'their', 'here', 'there', 'where', 'when', 
        'why', 'how', 'what', 'who', 'which', 'can', 'just', 'now', 'then',
        'so', 'very', 'too', 'much', 'many', 'some', 'any', 'all', 'no', 'not'
    },
    'pt': {
        'o', 'a', 'os', 'as', 'um', 'uma', 'uns', 'umas', 'e', 'ou', 'mas', 'em', 
        'no', 'na', 'nos', 'nas', 'para', 'por', 'com', 'sem', 'de', 'do', 'da', 
        'dos', 'das', '√©', 's√£o', 'foi', 'foram', 'ser', 'estar', 'ter', 'haver',
        'este', 'esta', 'estes', 'estas', 'esse', 'essa', 'esses', 'essas', 
        'aquele', 'aquela', 'aqueles', 'aquelas', 'eu', 'tu', 'ele', 'ela', 
        'n√≥s', 'v√≥s', 'eles', 'elas', 'me', 'te', 'se', 'nos', 'vos', 'lhe', 
        'lhes', 'meu', 'minha', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas',
        'seu', 'sua', 'seus', 'suas', 'nosso', 'nossa', 'nossos', 'nossas',
        'que', 'quem', 'qual', 'quais', 'onde', 'quando', 'como', 'por que',
        'porque', 'ent√£o', 'assim', 'muito', 'pouco', 'mais', 'menos', 'bem',
        'mal', 'j√°', 'ainda', 'sempre', 'nunca', 'aqui', 'a√≠', 'ali', 'l√°',
        'hoje', 'ontem', 'amanh√£', 'agora', 'depois', 'antes', 'sim', 'n√£o'
    }
}

class YouTubeRAGExtractor:
    """
    üé¨ Extrator RAG completo de v√≠deos do YouTube
    """
    
    def __init__(self, storage_dir: str = "storage", proxy: Optional[str] = None, use_tor: bool = False):
        """
        Inicializa o extrator RAG de v√≠deos do YouTube
        
        Args:
            storage_dir: Diret√≥rio principal de armazenamento
            proxy: Proxy no formato 'http://host:port' ou 'socks5://host:port'
            use_tor: Se True, tenta usar Tor (porta 9050)
        """
        self.storage_dir = Path(storage_dir)
        self.storage_dir.mkdir(exist_ok=True)
        
        # Configurar proxy
        self.proxy = proxy
        self.use_tor = use_tor
        if use_tor and not proxy:
            self.proxy = "socks5://127.0.0.1:9050"  # Tor padr√£o
        
        # Configurar estrutura de diret√≥rios baseada no sistema antigo
        self.setup_directory_structure()
        
        print(f"üé¨ YouTubeRAGExtractor inicializado")
        print(f"üìÅ Diret√≥rio de armazenamento: {self.storage_dir}")
        if self.proxy:
            print(f"üåê Usando proxy: {self.proxy}")
        elif self.use_tor:
            print(f"üßÖ Tentando usar Tor")
    
    def setup_directory_structure(self):
        """
        Configura a estrutura de diret√≥rios baseada no sistema antigo
        """
        # Estrutura base para dados extra√≠dos (similar ao sistema antigo)
        self.data_dir = self.storage_dir / "youtube_extracted_data"
        self.data_dir.mkdir(exist_ok=True)
        
        # Subdiret√≥rios especializados
        self.dirs = {
            'transcripts': self.data_dir / 'transcripts',
            'metadata': self.data_dir / 'metadata', 
            'chunks': self.data_dir / 'chunks',
            'rag_content': self.data_dir / 'rag_content',
            'database': self.data_dir / 'database'
        }
        
        # Criar todos os diret√≥rios
        for directory in self.dirs.values():
            directory.mkdir(exist_ok=True)
    
    def extract_video_id(self, url: str) -> Optional[str]:
        """
        Extrai ID do v√≠deo de URL do YouTube
        """
        try:
            patterns = [
                r'(?:youtube\.com/watch\?v=|youtu\.be/|youtube\.com/embed/)([^&\n?#]+)',
                r'youtube\.com/v/([^&\n?#]+)',
                r'youtube\.com/watch\?.*v=([^&\n?#]+)'
            ]
            
            for pattern in patterns:
                match = re.search(pattern, url)
                if match:
                    return match.group(1)
            
            if re.match(r'^[a-zA-Z0-9_-]{11}$', url):
                return url
                
            return None
            
        except Exception as e:
            logger.error(f"Erro ao extrair ID do v√≠deo: {e}")
            return None
    
    def extract_playlist_id(self, url: str) -> Optional[str]:
        """
        Extrai ID da playlist de URL do YouTube
        """
        try:
            patterns = [
                r'list=([^&\n?#]+)',
                r'playlist\?list=([^&\n?#]+)'
            ]
            
            for pattern in patterns:
                match = re.search(pattern, url)
                if match:
                    return match.group(1)
                    
            return None
            
        except Exception as e:
            logger.error(f"Erro ao extrair ID da playlist: {e}")
            return None
    
    def get_video_metadata(self, video_id: str) -> Dict[str, Any]:
        """
        Obt√©m metadados do v√≠deo usando yt-dlp com suporte a proxy
        """
        if not YT_DLP_AVAILABLE:
            return {'error': 'yt-dlp n√£o dispon√≠vel'}
        
        try:
            url = f'https://www.youtube.com/watch?v={video_id}'
            
            ydl_opts = {
                'quiet': True,
                'no_warnings': True,
                'extract_flat': False
            }
            
            # Adicionar configura√ß√£o de proxy se dispon√≠vel
            if self.proxy:
                ydl_opts['proxy'] = self.proxy
                print(f"üåê yt-dlp usando proxy: {self.proxy}")
            
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                info = ydl.extract_info(url, download=False)
                
                metadata = {
                    'video_id': video_id,
                    'title': info.get('title', ''),
                    'description': info.get('description', ''),
                    'uploader': info.get('uploader', ''),
                    'upload_date': info.get('upload_date', ''),
                    'duration': info.get('duration', 0),
                    'view_count': info.get('view_count', 0),
                    'like_count': info.get('like_count', 0),
                    'comment_count': info.get('comment_count', 0),
                    'thumbnail': info.get('thumbnail', ''),
                    'url': url,
                    'extraction_date': datetime.now().isoformat(),
                    'extractor_version': '3.0.0',
                    'proxy_used': self.proxy if self.proxy else None
                }
                
                return metadata
            
        except Exception as e:
            logger.error(f"Erro ao obter metadados: {e}")
            return {
                'video_id': video_id,
                'title': f'Video_{video_id}',
                'error': str(e),
                'extraction_date': datetime.now().isoformat()
            }
    
    def get_playlist_info(self, playlist_id: str) -> Dict[str, Any]:
        """
        Obt√©m informa√ß√µes completas da playlist incluindo nome
        """
        if not YT_DLP_AVAILABLE:
            return {}
        
        try:
            url = f'https://www.youtube.com/playlist?list={playlist_id}'
            
            ydl_opts = {
                'quiet': True,
                'no_warnings': True,
                'extract_flat': False  # Extrair metadados completos
            }
            
            # Adicionar configura√ß√£o de proxy se dispon√≠vel
            if self.proxy:
                ydl_opts['proxy'] = self.proxy
                print(f"üåê yt-dlp playlist usando proxy: {self.proxy}")
            
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                playlist_info = ydl.extract_info(url, download=False)
                
                # Extrair informa√ß√µes da playlist
                playlist_data = {
                    'id': playlist_id,
                    'title': playlist_info.get('title', f'playlist_{playlist_id}'),
                    'uploader': playlist_info.get('uploader', 'Unknown'),
                    'description': playlist_info.get('description', ''),
                    'video_count': len(playlist_info.get('entries', [])),
                    'url': url,
                    'extraction_timestamp': datetime.now().isoformat()
                }
                
                # Extrair IDs dos v√≠deos
                video_ids = []
                for entry in playlist_info.get('entries', []):
                    if entry and entry.get('id'):
                        video_ids.append(entry['id'])
                
                playlist_data['video_ids'] = video_ids
                
                print(f"üìã Playlist: '{playlist_data['title']}' ({len(video_ids)} v√≠deos)")
                return playlist_data
        
        except Exception as e:
            logger.error(f"Erro ao obter informa√ß√µes da playlist: {e}")
            # Fallback para m√©todo antigo
            return {
                'id': playlist_id,
                'title': f'playlist_{playlist_id}',
                'video_ids': self.get_playlist_videos(playlist_id)
            }

    def get_playlist_videos(self, playlist_id: str) -> List[str]:
        """
        Obt√©m lista de v√≠deos de uma playlist com suporte a proxy (m√©todo simplificado)
        """
        playlist_info = self.get_playlist_info(playlist_id)
        return playlist_info.get('video_ids', [])
    
    def get_transcript(self, video_id: str) -> Optional[Dict[str, Any]]:
        """
        Obt√©m transcri√ß√£o do v√≠deo com suporte a proxy/Tor
        """
        if not YOUTUBE_TRANSCRIPT_AVAILABLE:
            return None
        
        try:
            # Configurar proxy se dispon√≠vel
            import os
            original_proxies = {}
            
            if self.proxy:
                if self.proxy.startswith('socks'):
                    # Para SOCKS, precisamos configurar diferente
                    print(f"üåê Usando proxy SOCKS: {self.proxy}")
                    # Configurar via environment variables
                    original_proxies = {
                        'http_proxy': os.environ.get('http_proxy'),
                        'https_proxy': os.environ.get('https_proxy'),
                        'HTTP_PROXY': os.environ.get('HTTP_PROXY'),
                        'HTTPS_PROXY': os.environ.get('HTTPS_PROXY')
                    }
                    os.environ['http_proxy'] = self.proxy
                    os.environ['https_proxy'] = self.proxy
                    os.environ['HTTP_PROXY'] = self.proxy
                    os.environ['HTTPS_PROXY'] = self.proxy
                else:
                    print(f"üåê Usando proxy HTTP: {self.proxy}")
                    original_proxies = {
                        'http_proxy': os.environ.get('http_proxy'),
                        'https_proxy': os.environ.get('https_proxy')
                    }
                    os.environ['http_proxy'] = self.proxy
                    os.environ['https_proxy'] = self.proxy
            
            # Tentar m√∫ltiplas estrat√©gias para contornar bloqueios
            transcript_data = None
            errors = []
            
            # Estrat√©gia 1: Idiomas preferidos
            languages = ['pt', 'pt-BR', 'en', 'es']
            try:
                transcript_data = YouTubeTranscriptApi.get_transcript(video_id, languages=languages)
                print("‚úÖ Transcri√ß√£o obtida com idiomas preferidos")
            except Exception as e:
                errors.append(f"Idiomas preferidos: {str(e)}")
                
                # Estrat√©gia 2: Apenas ingl√™s
                try:
                    transcript_data = YouTubeTranscriptApi.get_transcript(video_id, languages=['en'])
                    print("‚úÖ Transcri√ß√£o obtida em ingl√™s")
                except Exception as e2:
                    errors.append(f"Ingl√™s: {str(e2)}")
                    
                    # Estrat√©gia 3: Listar e pegar qualquer dispon√≠vel
                    try:
                        transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)
                        available_transcripts = list(transcript_list)
                        if available_transcripts:
                            transcript = available_transcripts[0]
                            transcript_data = transcript.fetch()
                            print(f"‚úÖ Transcri√ß√£o obtida: {transcript.language}")
                        else:
                            errors.append("Nenhuma transcri√ß√£o dispon√≠vel")
                    except Exception as e3:
                        errors.append(f"Lista de transcri√ß√µes: {str(e3)}")
            
            # Restaurar configura√ß√µes de proxy
            if self.proxy:
                for key, value in original_proxies.items():
                    if value is None:
                        os.environ.pop(key, None)
                    else:
                        os.environ[key] = value
            
            if not transcript_data:
                print(f"‚ö†Ô∏è N√£o foi poss√≠vel obter transcri√ß√£o ap√≥s m√∫ltiplas tentativas:")
                for error in errors:
                    print(f"   - {error}")
                return None
            
            # Processar segmentos
            segments = []
            full_text = ""
            total_duration = 0
            
            for i, segment in enumerate(transcript_data):
                segment_info = {
                    'index': i,
                    'text': segment['text'].strip(),
                    'start': segment['start'],
                    'duration': segment['duration'],
                    'end': segment['start'] + segment['duration']
                }
                segments.append(segment_info)
                full_text += segment['text'] + " "
                total_duration = max(total_duration, segment_info['end'])
            
            # Detectar idioma e tipo
            language = 'en'
            is_generated = True
            
            try:
                transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)
                for transcript in transcript_list:
                    language = transcript.language_code
                    is_generated = transcript.is_generated
                    break
            except:
                pass
            
            return {
                'video_id': video_id,
                'language': language,
                'is_generated': is_generated,
                'segments': segments,
                'full_text': full_text.strip(),
                'total_segments': len(segments),
                'total_duration': total_duration,
                'extraction_timestamp': datetime.now().isoformat(),
                'transcript_info': {
                    'language': language,
                    'type': 'generated' if is_generated else 'manual'
                },
                'proxy_used': self.proxy if self.proxy else None
            }
            
        except Exception as e:
            logger.error(f"Erro ao obter transcri√ß√£o: {e}")
            return None
    
    def download_audio_and_transcribe(self, video_id: str, video_folder: Optional[Path] = None) -> Optional[Dict[str, Any]]:
        """
        Baixa √°udio do v√≠deo e faz transcri√ß√£o local - SOLU√á√ÉO DEFINITIVA PARA BLOQUEIO IP
        """
        import tempfile
        import os
        
        try:
            print("üéµ Baixando √°udio do v√≠deo...")
            
            url = f'https://www.youtube.com/watch?v={video_id}'
            
            # Criar diret√≥rio tempor√°rio para √°udio
            with tempfile.TemporaryDirectory() as temp_dir:
                audio_file = os.path.join(temp_dir, f"{video_id}.%(ext)s")
                
                # Configurar yt-dlp para baixar apenas √°udio (sem p√≥s-processamento)
                ydl_opts = {
                    'format': 'bestaudio/best',
                    'outtmpl': audio_file,
                    'quiet': True,
                    'no_warnings': True
                }
                
                # Configurar proxy se dispon√≠vel
                if self.proxy:
                    ydl_opts['proxy'] = self.proxy
                    print(f"üåê Download usando proxy: {self.proxy}")
                
                # Baixar √°udio
                with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                    try:
                        ydl.download([url])
                        print("‚úÖ √Åudio baixado com sucesso")
                        
                        # Encontrar arquivo de √°udio baixado
                        audio_files = [f for f in os.listdir(temp_dir) if f.startswith(video_id) and (f.endswith('.wav') or f.endswith('.webm') or f.endswith('.m4a') or f.endswith('.mp4'))]
                        
                        if not audio_files:
                            print("‚ùå Arquivo de √°udio n√£o encontrado")
                            print(f"üìÅ Arquivos no diret√≥rio: {os.listdir(temp_dir)}")
                            return None
                        
                        audio_path = os.path.join(temp_dir, audio_files[0])
                        print(f"üéµ Arquivo de √°udio: {audio_files[0]}")
                        print(f"üìÅ Caminho completo: {audio_path}")
                        
                        # Verificar se o arquivo existe
                        if not os.path.exists(audio_path):
                            print(f"‚ùå Arquivo n√£o existe: {audio_path}")
                            return None
                        
                        # Salvar c√≥pia do √°udio na pasta do v√≠deo para verifica√ß√£o
                        if video_folder:
                            try:
                                import shutil
                                video_folder.mkdir(exist_ok=True)
                                saved_audio_path = video_folder / f"audio_{video_id}{os.path.splitext(audio_files[0])[1]}"
                                shutil.copy2(audio_path, saved_audio_path)
                                print(f"üíæ √Åudio salvo em: {saved_audio_path}")
                            except Exception as e:
                                print(f"‚ö†Ô∏è Erro ao salvar √°udio: {e}")
                        
                        # Converter para WAV se necess√°rio (opcional, Whisper suporta webm)
                        if PYDUB_AVAILABLE and not audio_files[0].endswith('.wav'):
                            try:
                                audio = AudioSegment.from_file(audio_path)
                                wav_path = os.path.join(temp_dir, f"{video_id}.wav")
                                audio.export(wav_path, format='wav')
                                audio_path = wav_path
                                print("üîÑ Convertido para WAV")
                                
                                # Salvar vers√£o WAV tamb√©m se o video_folder estiver dispon√≠vel
                                if video_folder:
                                    try:
                                        wav_saved_path = video_folder / f"audio_{video_id}.wav"
                                        shutil.copy2(wav_path, wav_saved_path)
                                        print(f"üíæ √Åudio WAV salvo em: {wav_saved_path}")
                                    except Exception as e:
                                        print(f"‚ö†Ô∏è Erro ao salvar √°udio WAV: {e}")
                            except Exception as e:
                                print(f"‚ö†Ô∏è Erro na convers√£o para WAV: {e}")
                                print("üìù Usando arquivo original")
                        else:
                            print("üìù Usando arquivo de √°udio diretamente")
                        
                        # Tentar transcri√ß√£o com Whisper (melhor qualidade)
                        if WHISPER_AVAILABLE:
                            return self.transcribe_with_whisper(video_id, audio_path)
                        
                        # Fallback: SpeechRecognition
                        elif SPEECH_RECOGNITION_AVAILABLE and PYDUB_AVAILABLE:
                            return self.transcribe_with_speech_recognition(video_id, audio_path)
                        
                        else:
                            print("‚ùå Nenhuma biblioteca de transcri√ß√£o dispon√≠vel")
                            print("üí° Instale: pip install openai-whisper")
                            print("üí° Ou: pip install SpeechRecognition pydub")
                            return None
                    
                    except Exception as e:
                        print(f"‚ùå Erro no download: {e}")
                        return None
        
        except Exception as e:
            print(f"‚ùå Erro no processo de download/transcri√ß√£o: {e}")
            return None
    
    def transcribe_with_whisper(self, video_id: str, audio_path: str) -> Optional[Dict[str, Any]]:
        """
        Transcreve √°udio usando Whisper (OpenAI) - COM CONTROLE DE MEM√ìRIA
        """
        try:
            print("üß† Transcrevendo com Whisper...")
            
            # Verificar se arquivo existe
            if not os.path.exists(audio_path):
                print(f"‚ùå Arquivo n√£o encontrado: {audio_path}")
                return None
            
            print(f"üìÅ Transcrevendo arquivo: {audio_path}")
            file_size_mb = os.path.getsize(audio_path) / (1024 * 1024)
            print(f"üìä Tamanho do arquivo: {file_size_mb:.2f} MB")
            
            # CONTROLE DE MEM√ìRIA - Evitar sobrecarga que causa desligamento
            import gc
            import torch
            
            # Limpar cache antes de come√ßar
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            # Usar modelo mais leve para arquivos grandes
            model_size = "tiny" if file_size_mb > 10 else "base"
            print(f"üîß Usando modelo Whisper: {model_size}")
            
            # Carregar modelo com configura√ß√µes otimizadas
            model = whisper.load_model(model_size, device="cpu")  # For√ßar CPU para estabilidade
            
            # Transcrever com detec√ß√£o autom√°tica de idioma
            print("üîç Detectando idioma automaticamente...")
            result = model.transcribe(
                audio_path,
                language=None,  # Detec√ß√£o autom√°tica de idioma
                fp16=False,     # Usar FP32 no CPU
                verbose=False,  # Menos verbose
                beam_size=1,    # Reduzir beam search para economizar mem√≥ria
                best_of=1,      # Reduzir n√∫mero de tentativas
                temperature=0   # Determin√≠stico
            )
            
            detected_language = result.get('language', 'unknown')
            print(f"üåç Idioma detectado: {detected_language}")
            
            # Limpar modelo da mem√≥ria imediatamente
            del model
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            print("üßπ Mem√≥ria limpa ap√≥s transcri√ß√£o")
            
            # Processar resultado
            segments = []
            full_text = result.get('text', '')
            
            # Whisper retorna segmentos com timestamps
            for i, segment in enumerate(result.get('segments', [])):
                segment_info = {
                    'index': i,
                    'text': segment.get('text', '').strip(),
                    'start': segment.get('start', 0),
                    'end': segment.get('end', 0),
                    'duration': segment.get('end', 0) - segment.get('start', 0)
                }
                segments.append(segment_info)
            
            # Se n√£o h√° segmentos mas h√° texto, criar um segmento √∫nico
            if not segments and full_text.strip():
                segments = [{
                    'index': 0,
                    'text': full_text.strip(),
                    'start': 0,
                    'end': 180,  # Aproximar 3 minutos
                    'duration': 180
                }]
            
            print(f"‚úÖ Whisper: {len(segments)} segmentos transcritos")
            print(f"üìù Texto: {full_text[:100]}..." if len(full_text) > 100 else f"üìù Texto: {full_text}")
            
            return {
                'video_id': video_id,
                'language': detected_language,
                'is_generated': True,
                'segments': segments,
                'full_text': full_text.strip(),
                'total_segments': len(segments),
                'total_duration': segments[-1]['end'] if segments else 0,
                'extraction_timestamp': datetime.now().isoformat(),
                'transcript_info': {
                    'language': detected_language,
                    'type': 'whisper_local',
                    'model_size': model_size
                },
                'source': 'whisper_audio_download',
                'quality': 'high'
            }
        
        except Exception as e:
            print(f"‚ùå Erro no Whisper: {e}")
            print(f"‚ùå Tipo do erro: {type(e)}")
            import traceback
            print(f"‚ùå Traceback: {traceback.format_exc()}")
            return None
    
    def transcribe_with_speech_recognition(self, video_id: str, audio_path: str) -> Optional[Dict[str, Any]]:
        """
        Transcreve √°udio usando SpeechRecognition - FALLBACK
        """
        try:
            print("üé§ Transcrevendo com SpeechRecognition...")
            
            # Converter √°udio para WAV se necess√°rio
            audio = AudioSegment.from_file(audio_path)
            wav_path = audio_path.rsplit('.', 1)[0] + '.wav'
            audio.export(wav_path, format='wav')
            
            # Configurar recognizer
            recognizer = sr.Recognizer()
            
            # Dividir √°udio em chunks para processamento
            chunk_duration = 30000  # 30 segundos por chunk
            chunks = []
            full_text = ""
            
            for i, chunk_start in enumerate(range(0, len(audio), chunk_duration)):
                chunk_end = min(chunk_start + chunk_duration, len(audio))
                chunk = audio[chunk_start:chunk_end]
                
                # Salvar chunk tempor√°rio
                chunk_path = f"{wav_path}_chunk_{i}.wav"
                chunk.export(chunk_path, format='wav')
                
                try:
                    # Transcrever chunk
                    with sr.AudioFile(chunk_path) as source:
                        audio_data = recognizer.record(source)
                        text = recognizer.recognize_google(audio_data, language='pt-BR')
                        
                        if text.strip():
                            chunk_info = {
                                'index': i,
                                'text': text.strip(),
                                'start': chunk_start / 1000,  # Converter para segundos
                                'end': chunk_end / 1000,
                                'duration': (chunk_end - chunk_start) / 1000
                            }
                            chunks.append(chunk_info)
                            full_text += text + " "
                
                except sr.UnknownValueError:
                    # Chunk sem fala reconhec√≠vel
                    pass
                except sr.RequestError as e:
                    print(f"‚ö†Ô∏è Erro no Google Speech API: {e}")
                
                # Limpar chunk tempor√°rio
                try:
                    os.remove(chunk_path)
                except:
                    pass
            
            # Limpar arquivo WAV tempor√°rio
            try:
                os.remove(wav_path)
            except:
                pass
            
            if chunks:
                print(f"‚úÖ SpeechRecognition: {len(chunks)} chunks transcritos")
                
                return {
                    'video_id': video_id,
                    'language': 'pt-BR',
                    'is_generated': True,
                    'segments': chunks,
                    'full_text': full_text.strip(),
                    'total_segments': len(chunks),
                    'total_duration': chunks[-1]['end'] if chunks else 0,
                    'extraction_timestamp': datetime.now().isoformat(),
                    'transcript_info': {
                        'language': 'pt-BR',
                        'type': 'speech_recognition_local'
                    },
                    'source': 'speech_recognition_audio_download',
                    'quality': 'medium'
                }
            else:
                print("‚ùå Nenhum texto reconhecido")
                return None
        
        except Exception as e:
            print(f"‚ùå Erro no SpeechRecognition: {e}")
            return None

    def get_transcript_with_fallbacks(self, video_id: str, video_folder: Optional[Path] = None) -> Optional[Dict[str, Any]]:
        """
        Tenta m√∫ltiplas estrat√©gias para obter transcri√ß√£o - INCLUINDO DOWNLOAD LOCAL
        """
        try:
            # Estrat√©gia 1: youtube-transcript-api direto
            print("üìù Tentando: youtube-transcript-api direto...")
            transcript = self.get_transcript(video_id)
            if transcript and transcript.get('segments'):
                print("‚úÖ Sucesso com youtube-transcript-api direto")
                transcript['source'] = 'youtube_transcript_api_direct'
                return transcript
            
            print("‚ùå Falhou: youtube-transcript-api direto")
            
            # Estrat√©gia 2: youtube-transcript-api com proxy
            if self.proxy:
                print("üìù Tentando: youtube-transcript-api com proxy...")
                transcript = self.get_transcript(video_id)
                if transcript and transcript.get('segments'):
                    print("‚úÖ Sucesso com youtube-transcript-api + proxy")
                    transcript['source'] = 'youtube_transcript_api_proxy'
                    return transcript
                
                print("‚ùå Falhou: youtube-transcript-api com proxy")
            
            # Estrat√©gia 3: yt-dlp subtitles
            print("üìù Tentando: yt-dlp subtitles...")
            transcript = self.extract_subtitles_with_ydl(video_id)
            if transcript and transcript.get('segments'):
                print("‚úÖ Sucesso com yt-dlp subtitles")
                transcript['source'] = 'ytdlp_subtitles'
                return transcript
            
            print("‚ùå Falhou: yt-dlp subtitles")
            
            # Estrat√©gia 4: DOWNLOAD DE √ÅUDIO + TRANSCRI√á√ÉO LOCAL (SOLU√á√ÉO DEFINITIVA)
            print("üìù Tentando: Download de √°udio + transcri√ß√£o local...")
            transcript = self.download_audio_and_transcribe(video_id, video_folder)
            if transcript and transcript.get('segments'):
                print("‚úÖ Sucesso com download de √°udio + transcri√ß√£o local")
                return transcript
            
            print("‚ùå Falhou: Download de √°udio + transcri√ß√£o local")
            
            print("‚ùå Todas as estrat√©gias falharam para:", video_id)
            return None
        
        except Exception as e:
            print(f"‚ùå Erro em get_transcript_with_fallbacks: {e}")
            return None
    
    def extract_subtitles_with_ydl(self, video_id: str) -> Optional[Dict[str, Any]]:
        """
        Extrai legendas usando yt-dlp como fallback
        """
        import tempfile
        import os
        
        try:
            url = f'https://www.youtube.com/watch?v={video_id}'
            
            # Criar diret√≥rio tempor√°rio
            with tempfile.TemporaryDirectory() as temp_dir:
                output_template = os.path.join(temp_dir, f"{video_id}.%(ext)s")
                
                ydl_opts = {
                    'writesubtitles': True,
                    'writeautomaticsub': True,
                    'skip_download': True,
                    'outtmpl': output_template,
                    'quiet': True,
                    'no_warnings': True,
                    'subtitleslangs': ['pt', 'pt-BR', 'en'],
                    'subtitlesformat': 'vtt'
                }
                
                if self.proxy:
                    ydl_opts['proxy'] = self.proxy
                
                with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                    try:
                        # Extrair informa√ß√µes e baixar legendas
                        info = ydl.extract_info(url, download=False)
                        
                        # Verificar quais legendas est√£o dispon√≠veis
                        subtitles = info.get('subtitles', {})
                        automatic_captions = info.get('automatic_captions', {})
                        
                        all_subs = {**subtitles, **automatic_captions}
                        
                        # Tentar baixar legendas na ordem de prefer√™ncia
                        for lang in ['pt', 'pt-BR', 'en']:
                            if lang in all_subs:
                                print(f"üîΩ Baixando legenda em {lang}...")
                                
                                # Baixar s√≥ essa legenda espec√≠fica
                                ydl_opts_specific = ydl_opts.copy()
                                ydl_opts_specific['subtitleslangs'] = [lang]
                                
                                with yt_dlp.YoutubeDL(ydl_opts_specific) as ydl_specific:
                                    ydl_specific.download([url])
                                
                                # Procurar arquivo de legenda baixado
                                vtt_file = os.path.join(temp_dir, f"{video_id}.{lang}.vtt")
                                if os.path.exists(vtt_file):
                                    with open(vtt_file, 'r', encoding='utf-8') as f:
                                        vtt_content = f.read()
                                    
                                    return self.parse_vtt_content(video_id, vtt_content, lang)
                        
                        # Se n√£o conseguiu com idiomas espec√≠ficos, tentar qualquer um
                        for lang_code in all_subs.keys():
                            print(f"üîΩ Tentando baixar legenda em {lang_code}...")
                            
                            ydl_opts_any = ydl_opts.copy()
                            ydl_opts_any['subtitleslangs'] = [lang_code]
                            
                            with yt_dlp.YoutubeDL(ydl_opts_any) as ydl_any:
                                try:
                                    ydl_any.download([url])
                                    
                                    vtt_file = os.path.join(temp_dir, f"{video_id}.{lang_code}.vtt")
                                    if os.path.exists(vtt_file):
                                        with open(vtt_file, 'r', encoding='utf-8') as f:
                                            vtt_content = f.read()
                                        
                                        return self.parse_vtt_content(video_id, vtt_content, lang_code)
                                except:
                                    continue
                    
                    except Exception as e:
                        print(f"Erro ao extrair com yt-dlp: {e}")
        
        except Exception as e:
            print(f"Erro no m√©todo yt-dlp: {e}")
        
        return None
    
    def parse_vtt_content(self, video_id: str, vtt_content: str, language: str) -> Dict[str, Any]:
        """
        Parseia conte√∫do VTT e retorna estrutura de transcri√ß√£o
        """
        try:
            segments = []
            full_text = ""
            lines = vtt_content.split('\n')
            
            current_segment = None
            segment_index = 0
            
            for line in lines:
                line = line.strip()
                
                # Pular linhas vazias e cabe√ßalhos
                if not line or line.startswith('WEBVTT') or line.startswith('NOTE'):
                    continue
                
                # Linha de tempo: 00:00:01.000 --> 00:00:05.000
                if '-->' in line:
                    try:
                        times = line.split('-->')
                        start_time = self.parse_vtt_time(times[0].strip())
                        end_time = self.parse_vtt_time(times[1].strip())
                        
                        current_segment = {
                            'index': segment_index,
                            'start': start_time,
                            'end': end_time,
                            'duration': end_time - start_time,
                            'text': ''
                        }
                    except:
                        continue
                
                # Texto da legenda
                elif line and current_segment is not None:
                    # Remover tags HTML e formata√ß√£o
                    clean_text = re.sub(r'<[^>]+>', '', line)
                    clean_text = clean_text.replace('&amp;', '&').replace('&lt;', '<').replace('&gt;', '>')
                    clean_text = clean_text.strip()
                    
                    if clean_text:
                        if current_segment['text']:
                            current_segment['text'] += ' ' + clean_text
                        else:
                            current_segment['text'] = clean_text
                
                # Linha vazia indica fim do segmento
                elif not line and current_segment is not None and current_segment['text']:
                    segments.append(current_segment)
                    full_text += current_segment['text'] + ' '
                    segment_index += 1
                    current_segment = None
            
            # Adicionar √∫ltimo segmento se necess√°rio
            if current_segment is not None and current_segment['text']:
                segments.append(current_segment)
                full_text += current_segment['text'] + ' '
            
            if segments:
                print(f"‚úÖ Extra√≠dos {len(segments)} segmentos via yt-dlp")
                
                return {
                    'video_id': video_id,
                    'language': language,
                    'is_generated': True,
                    'segments': segments,
                    'full_text': full_text.strip(),
                    'total_segments': len(segments),
                    'total_duration': segments[-1]['end'] if segments else 0,
                    'extraction_timestamp': datetime.now().isoformat(),
                    'transcript_info': {
                        'language': language,
                        'type': 'ydl_extracted'
                    },
                    'source': 'yt-dlp_subtitles'
                }
        
        except Exception as e:
            print(f"Erro ao parsear VTT: {e}")
        
        return None
    
    def parse_vtt_time(self, time_str: str) -> float:
        """
        Converte timestamp VTT para segundos
        """
        try:
            # Remove espa√ßos e normaliza
            time_str = time_str.strip().replace(',', '.')
            
            # Formato: HH:MM:SS.mmm ou MM:SS.mmm
            parts = time_str.split(':')
            
            if len(parts) == 3:  # HH:MM:SS.mmm
                hours = float(parts[0])
                minutes = float(parts[1])
                seconds = float(parts[2])
                return hours * 3600 + minutes * 60 + seconds
            elif len(parts) == 2:  # MM:SS.mmm
                minutes = float(parts[0])
                seconds = float(parts[1])
                return minutes * 60 + seconds
            else:
                return float(parts[0])
        except:
            return 0.0
        """
        Obt√©m transcri√ß√£o do v√≠deo com suporte a proxy/Tor
        """
        if not YOUTUBE_TRANSCRIPT_AVAILABLE:
            return None
        
        try:
            # Configurar proxy se dispon√≠vel
            import os
            original_proxies = {}
            
            if self.proxy:
                if self.proxy.startswith('socks'):
                    # Para SOCKS, precisamos configurar diferente
                    print(f"üåê Usando proxy SOCKS: {self.proxy}")
                    # Configurar via environment variables
                    original_proxies = {
                        'http_proxy': os.environ.get('http_proxy'),
                        'https_proxy': os.environ.get('https_proxy'),
                        'HTTP_PROXY': os.environ.get('HTTP_PROXY'),
                        'HTTPS_PROXY': os.environ.get('HTTPS_PROXY')
                    }
                    os.environ['http_proxy'] = self.proxy
                    os.environ['https_proxy'] = self.proxy
                    os.environ['HTTP_PROXY'] = self.proxy
                    os.environ['HTTPS_PROXY'] = self.proxy
                else:
                    print(f"üåê Usando proxy HTTP: {self.proxy}")
                    original_proxies = {
                        'http_proxy': os.environ.get('http_proxy'),
                        'https_proxy': os.environ.get('https_proxy')
                    }
                    os.environ['http_proxy'] = self.proxy
                    os.environ['https_proxy'] = self.proxy
            
            # Tentar m√∫ltiplas estrat√©gias para contornar bloqueios
            transcript_data = None
            errors = []
            
            # Estrat√©gia 1: Idiomas preferidos
            languages = ['pt', 'pt-BR', 'en', 'es']
            try:
                transcript_data = YouTubeTranscriptApi.get_transcript(video_id, languages=languages)
                print("‚úÖ Transcri√ß√£o obtida com idiomas preferidos")
            except Exception as e:
                errors.append(f"Idiomas preferidos: {str(e)}")
                
                # Estrat√©gia 2: Apenas ingl√™s
                try:
                    transcript_data = YouTubeTranscriptApi.get_transcript(video_id, languages=['en'])
                    print("‚úÖ Transcri√ß√£o obtida em ingl√™s")
                except Exception as e2:
                    errors.append(f"Ingl√™s: {str(e2)}")
                    
                    # Estrat√©gia 3: Listar e pegar qualquer dispon√≠vel
                    try:
                        transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)
                        available_transcripts = list(transcript_list)
                        if available_transcripts:
                            transcript = available_transcripts[0]
                            transcript_data = transcript.fetch()
                            print(f"‚úÖ Transcri√ß√£o obtida: {transcript.language}")
                        else:
                            errors.append("Nenhuma transcri√ß√£o dispon√≠vel")
                    except Exception as e3:
                        errors.append(f"Lista de transcri√ß√µes: {str(e3)}")
            
            # Restaurar configura√ß√µes de proxy
            if self.proxy:
                for key, value in original_proxies.items():
                    if value is None:
                        os.environ.pop(key, None)
                    else:
                        os.environ[key] = value
            
            if not transcript_data:
                print(f"‚ö†Ô∏è N√£o foi poss√≠vel obter transcri√ß√£o ap√≥s m√∫ltiplas tentativas:")
                for error in errors:
                    print(f"   - {error}")
                return None
            
            # Processar segmentos
            segments = []
            full_text = ""
            total_duration = 0
            
            for i, segment in enumerate(transcript_data):
                segment_info = {
                    'index': i,
                    'text': segment['text'].strip(),
                    'start': segment['start'],
                    'duration': segment['duration'],
                    'end': segment['start'] + segment['duration']
                }
                segments.append(segment_info)
                full_text += segment['text'] + " "
                total_duration = max(total_duration, segment_info['end'])
            
            # Detectar idioma e tipo
            language = 'en'
            is_generated = True
            
            try:
                transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)
                for transcript in transcript_list:
                    language = transcript.language_code
                    is_generated = transcript.is_generated
                    break
            except:
                pass
            
            return {
                'video_id': video_id,
                'language': language,
                'is_generated': is_generated,
                'segments': segments,
                'full_text': full_text.strip(),
                'total_segments': len(segments),
                'total_duration': total_duration,
                'extraction_timestamp': datetime.now().isoformat(),
                'transcript_info': {
                    'language': language,
                    'type': 'generated' if is_generated else 'manual'
                },
                'proxy_used': self.proxy if self.proxy else None
            }
            
        except Exception as e:
            logger.error(f"Erro ao obter transcri√ß√£o: {e}")
            return None
    
    def filter_keywords(self, words: List[str], language: str = 'en') -> List[str]:
        """
        Filtra palavras removendo conectivos e palavras de baixo significado
        """
        stop_words = STOP_WORDS.get(language, STOP_WORDS['en'])
        
        filtered_words = []
        for word in words:
            clean_word = re.sub(r'[^\w]', '', word.lower())
            
            if (len(clean_word) >= 3 and 
                clean_word not in stop_words and
                not clean_word.isdigit()):
                filtered_words.append(clean_word)
        
        return filtered_words
    
    def extract_text_from_segments(self, segments: List[Dict]) -> str:
        """
        Extrai texto simples dos segmentos de transcri√ß√£o
        """
        if not segments:
            return ""
        
        text_parts = []
        for segment in segments:
            if isinstance(segment, dict):
                text = segment.get('text', '') or segment.get('content', '')
            else:
                text = str(segment)
            
            if text.strip():
                text_parts.append(text.strip())
        
        return "\n".join(text_parts)
    
    def create_chunks(self, text: str, chunk_size: int = 500, overlap: int = 100) -> List[Dict[str, Any]]:
        """
        Cria chunks do texto para RAG com controle de mem√≥ria otimizado
        """
        import gc
        import psutil
        
        # Verificar mem√≥ria dispon√≠vel
        try:
            import psutil
            memory = psutil.virtual_memory()
            if memory.percent > 85:
                print("‚ö†Ô∏è Mem√≥ria alta detectada, reduzindo tamanho dos chunks")
                chunk_size = 300
                overlap = 50
        except ImportError:
            pass  # Se psutil n√£o estiver dispon√≠vel, usar valores padr√£o
        except:
            pass  # Se psutil falhar, continuar com valores padr√£o
        
        chunks = []
        start = 0
        chunk_index = 0
        max_chunks = 30  # Limitar n√∫mero de chunks para evitar sobrecarga
        
        # Limitar texto se muito grande
        if len(text) > 30000:  # 30KB limite
            print("‚ö†Ô∏è Texto muito grande, truncando para evitar sobrecarga de mem√≥ria")
            text = text[:30000]
        
        try:
            while start < len(text) and chunk_index < max_chunks:
                end = start + chunk_size
                
                if end < len(text):
                    sentence_breaks = ['. ', '! ', '? ', '\n\n']
                    best_break = end
                    
                    for break_char in sentence_breaks:
                        break_pos = text.rfind(break_char, start, end + 100)
                        if break_pos > start:
                            best_break = break_pos + len(break_char)
                            break
                    
                    end = best_break
                
                chunk_text = text[start:end].strip()
                
                if chunk_text:
                    chunk = {
                        'index': chunk_index,
                        'text': chunk_text,
                        'start_char': start,
                        'end_char': end,
                        'char_count': len(chunk_text),
                        'word_count': len(chunk_text.split()),
                        'metadata': {
                            'chunk_size': chunk_size,
                            'overlap': overlap
                        }
                    }
                    chunks.append(chunk)
                    chunk_index += 1
                
                start = end - overlap
                if start >= len(text):
                    break
                
                # Limpeza de mem√≥ria a cada 5 chunks
                if chunk_index % 5 == 0:
                    gc.collect()
                    try:
                        import psutil
                        memory = psutil.virtual_memory()
                        if memory.percent > 90:
                            print(f"‚ö†Ô∏è Mem√≥ria cr√≠tica ({memory.percent}%), parando cria√ß√£o de chunks")
                            break
                    except ImportError:
                        pass  # psutil n√£o dispon√≠vel
                    except:
                        pass
            
            print(f"üìä Chunks criados: {len(chunks)} (m√°ximo permitido: {max_chunks})")
            return chunks
            
        except Exception as e:
            print(f"‚ùå Erro na cria√ß√£o de chunks: {e}")
            gc.collect()
            return []
    
    def analyze_content(self, transcript_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        An√°lise leve do conte√∫do para RAG com controle de mem√≥ria
        """
        try:
            import gc
            
            full_text = transcript_data.get('full_text', '')
            segments = transcript_data.get('segments', [])
            
            if not full_text:
                return {}
            
            # Limitar tamanho do texto para an√°lise
            if len(full_text) > 20000:  # 20KB limite
                print("‚ö†Ô∏è Texto muito grande para an√°lise, truncando...")
                full_text = full_text[:20000]
            
            # An√°lise b√°sica e leve
            words = full_text.split()[:1000]  # Limitar palavras analisadas
            sentences = [s for s in full_text.split('.')[:50] if s.strip()]  # Limitar senten√ßas
            
            # Keywords filtradas (limitado)
            word_freq = Counter(words)
            most_common_words = [word for word, count in word_freq.most_common(20)]  # Reduzido de 50 para 20
            language = transcript_data.get('language', 'en')
            filtered_keywords = self.filter_keywords(most_common_words, language)
            
            # An√°lise simplificada
            analysis = {
                'summary': {
                    'total_words': len(words),
                    'total_sentences': len(sentences),
                    'avg_words_per_sentence': len(words) / max(len(sentences), 1),
                    'language': language
                },
                'keywords': filtered_keywords[:15],  # Limitado a 15 keywords
                'metadata': {
                    'analysis_version': '2.0_light',
                    'timestamp': datetime.now().isoformat(),
                    'processing_mode': 'memory_optimized'
                }
            }
            
            # Limpeza imediata
            words = None
            sentences = None
            word_freq = None
            most_common_words = None
            filtered_keywords = None
            gc.collect()
            
            return analysis
            
        except Exception as e:
            print(f"‚ùå Erro na an√°lise: {e}")
            import gc
            gc.collect()
            return {
                'error': str(e),
                'metadata': {
                    'analysis_version': '2.0_light',
                    'timestamp': datetime.now().isoformat(),
                    'processing_mode': 'error_fallback'
                }
            }
            
            # An√°lise de legibilidade
            readability_score = 0
            if sentences:
                avg_words_per_sentence = len(words) / len(sentences)
                readability_score = max(0, min(100, 206.835 - (1.015 * avg_words_per_sentence)))
            
            # Identifica√ß√£o de t√≥picos
            topics = []
            tech_keywords = ['technology', 'software', 'computer', 'digital', 'app', 'web', 'api', 'code', 'programming',
                           'tecnologia', 'software', 'computador', 'digital', 'aplicativo', 'c√≥digo', 'programa√ß√£o']
            if any(keyword.lower() in full_text.lower() for keyword in tech_keywords):
                topics.append('tecnologia')
            
            # An√°lise de sentimento
            positive_words = ['good', 'great', 'excellent', 'amazing', 'wonderful', 'fantastic', 'perfect',
                            'bom', '√≥timo', 'excelente', 'fant√°stico', 'maravilhoso']
            negative_words = ['bad', 'terrible', 'awful', 'horrible', 'worst', 'hate', 'problem',
                            'ruim', 'p√©ssimo', 'terr√≠vel', 'horr√≠vel', 'pior', '√≥dio', 'problema']
            
            positive_count = sum(1 for word in positive_words if word.lower() in full_text.lower())
            negative_count = sum(1 for word in negative_words if word.lower() in full_text.lower())
            
            if positive_count > negative_count:
                sentiment = 'positive'
            elif negative_count > positive_count:
                sentiment = 'negative'
            else:
                sentiment = 'neutral'
            
            return {
                'statistics': {
                    'total_characters': len(full_text),
                    'total_words': len(words),
                    'total_sentences': len(sentences),
                    'average_words_per_segment': len(words) / len(segments) if segments else 0,
                    'total_duration_minutes': transcript_data.get('total_duration', 0) / 60
                },
                'content_analysis': {
                    'language_detected': language,
                    'transcript_type': transcript_data.get('transcript_info', {}).get('type', 'unknown'),
                    'readability_score': readability_score
                },
                'keywords': filtered_keywords[:10],
                'topics': topics,
                'sentiment': sentiment
            }
            
        except Exception as e:
            logger.error(f"Erro na an√°lise de conte√∫do: {e}")
            return {'error': str(e)}
    
    def create_database(self) -> str:
        """
        Cria banco SQLite com estrutura baseada no sistema antigo
        """
        try:
            db_path = self.dirs['database'] / "youtube_transcripts.db"
            
            conn = sqlite3.connect(str(db_path))
            cursor = conn.cursor()
            
            # Tabela de metadados
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS video_metadata (
                    video_id TEXT PRIMARY KEY,
                    title TEXT,
                    description TEXT,
                    uploader TEXT,
                    upload_date TEXT,
                    duration INTEGER,
                    view_count INTEGER,
                    like_count INTEGER,
                    extraction_date TEXT,
                    extractor_version TEXT
                )
            ''')
            
            # Tabela de segmentos de transcri√ß√£o
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS transcript_segments (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    video_id TEXT,
                    segment_index INTEGER,
                    text TEXT,
                    start_time REAL,
                    duration REAL,
                    end_time REAL,
                    FOREIGN KEY (video_id) REFERENCES video_metadata (video_id)
                )
            ''')
            
            # Tabela de chunks para RAG
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS content_chunks (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    video_id TEXT,
                    chunk_index INTEGER,
                    text TEXT,
                    start_char INTEGER,
                    end_char INTEGER,
                    char_count INTEGER,
                    word_count INTEGER,
                    FOREIGN KEY (video_id) REFERENCES video_metadata (video_id)
                )
            ''')
            
            # Tabela de an√°lises
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS content_analysis (
                    video_id TEXT PRIMARY KEY,
                    language_detected TEXT,
                    transcript_type TEXT,
                    total_characters INTEGER,
                    total_words INTEGER,
                    total_segments INTEGER,
                    keywords TEXT,
                    topics TEXT,
                    sentiment TEXT,
                    FOREIGN KEY (video_id) REFERENCES video_metadata (video_id)
                )
            ''')
            
            conn.commit()
            conn.close()
            
            return str(db_path)
            
        except Exception as e:
            logger.error(f"Erro ao criar banco de dados: {e}")
            return ""
    
    def save_to_database(self, db_path: str, video_id: str, metadata: Dict, transcript: Optional[Dict], 
                        chunks: List[Dict], analysis: Dict) -> bool:
        """
        Salva dados no banco SQLite
        """
        try:
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()
            
            # Inserir metadados
            cursor.execute('''
                INSERT OR REPLACE INTO video_metadata 
                (video_id, title, description, uploader, upload_date, duration, view_count, like_count, extraction_date, extractor_version)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                video_id,
                metadata.get('title', ''),
                metadata.get('description', ''),
                metadata.get('uploader', ''),
                metadata.get('upload_date', ''),
                metadata.get('duration', 0),
                metadata.get('view_count', 0),
                metadata.get('like_count', 0),
                metadata.get('extraction_date', ''),
                metadata.get('extractor_version', '3.0.0')
            ))
            
            # Inserir segmentos de transcri√ß√£o
            if transcript and transcript.get('segments'):
                for segment in transcript['segments']:
                    cursor.execute('''
                        INSERT INTO transcript_segments 
                        (video_id, segment_index, text, start_time, duration, end_time)
                        VALUES (?, ?, ?, ?, ?, ?)
                    ''', (
                        video_id,
                        segment.get('index', 0),
                        segment.get('text', ''),
                        segment.get('start', 0),
                        segment.get('duration', 0),
                        segment.get('end', 0)
                    ))
            
            # Inserir chunks
            for chunk in chunks:
                cursor.execute('''
                    INSERT INTO content_chunks 
                    (video_id, chunk_index, text, start_char, end_char, char_count, word_count)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                ''', (
                    video_id,
                    chunk.get('index', 0),
                    chunk.get('text', ''),
                    chunk.get('start_char', 0),
                    chunk.get('end_char', 0),
                    chunk.get('char_count', 0),
                    chunk.get('word_count', 0)
                ))
            
            # Inserir an√°lise
            if analysis:
                cursor.execute('''
                    INSERT OR REPLACE INTO content_analysis 
                    (video_id, language_detected, transcript_type, total_characters, total_words, total_segments, keywords, topics, sentiment)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    video_id,
                    analysis.get('content_analysis', {}).get('language_detected', ''),
                    analysis.get('content_analysis', {}).get('transcript_type', ''),
                    analysis.get('statistics', {}).get('total_characters', 0),
                    analysis.get('statistics', {}).get('total_words', 0),
                    analysis.get('statistics', {}).get('total_segments', 0),
                    json.dumps(analysis.get('keywords', [])),
                    json.dumps(analysis.get('topics', [])),
                    analysis.get('sentiment', 'neutral')
                ))
            
            conn.commit()
            conn.close()
            
            return True
            
        except Exception as e:
            logger.error(f"Erro ao salvar no banco: {e}")
            return False
    
    def create_video_folder_name(self, title: str, video_id: str) -> str:
        """
        Cria nome da pasta do v√≠deo (30 caracteres)
        """
        try:
            clean_title = re.sub(r'[<>:"/\\|?*]', '', title)
            clean_title = clean_title.strip()
            
            if len(clean_title) > 30:
                folder_name = clean_title[:30].strip()
            else:
                folder_name = clean_title
            
            if not folder_name:
                folder_name = video_id[:11]
            
            return folder_name
            
        except:
            return video_id[:11]
    
    def get_next_version_folder(self, base_folder_name: str, parent_dir: Path) -> str:
        """
        Obt√©m pr√≥xima vers√£o da pasta (controle de vers√£o)
        """
        version = 1
        folder_name = base_folder_name
        
        while (parent_dir / folder_name).exists():
            version += 1
            folder_name = f"{base_folder_name}_v{version}"
        
        return folder_name
    
    def create_playlist_folder_name(self, playlist_title: str, playlist_id: str) -> str:
        """
        Cria nome da pasta da playlist baseado no t√≠tulo real
        """
        try:
            # Limpar caracteres especiais
            clean_title = re.sub(r'[<>:"/\\|?*]', '', playlist_title)
            clean_title = re.sub(r'\s+', ' ', clean_title).strip()
            
            # Limitar a 50 caracteres para playlists (mais espa√ßo que v√≠deos individuais)
            if len(clean_title) > 50:
                folder_name = clean_title[:50].strip()
            else:
                folder_name = clean_title
            
            # Fallback se n√£o h√° t√≠tulo v√°lido
            if not folder_name:
                folder_name = f"playlist_{playlist_id}"
            
            return folder_name
            
        except:
            return f"playlist_{playlist_id}"
    
    def get_versioned_playlist_folder(self, base_name: str, storage_dir: Path) -> str:
        """
        Cria pasta da playlist com versionamento se j√° existir
        """
        base_path = storage_dir / base_name
        
        if not base_path.exists():
            return base_name
        
        # Se existe, criar vers√£o numerada
        version = 1
        while True:
            versioned_name = f"{base_name}_v{version}"
            versioned_path = storage_dir / versioned_name
            
            if not versioned_path.exists():
                print(f"üìÅ Pasta da playlist j√° existe, criando: {versioned_name}")
                return versioned_name
            
            version += 1
            
            # Seguran√ßa
            if version > 100:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                return f"{base_name}_{timestamp}"
    
    def download_thumbnail(self, video_id: str, thumbnail_url: str, output_dir: Path) -> Optional[str]:
        """
        Baixa thumbnail do v√≠deo
        """
        if not WEB_SCRAPING_AVAILABLE or not thumbnail_url:
            return None
        
        try:
            response = requests.get(thumbnail_url, timeout=10)
            response.raise_for_status()
            
            thumbnail_path = output_dir / f"{video_id}_thumbnail.jpg"
            
            with open(thumbnail_path, 'wb') as f:
                f.write(response.content)
            
            return str(thumbnail_path)
            
        except Exception as e:
            logger.warning(f"N√£o foi poss√≠vel baixar thumbnail: {e}")
            return None
    
    def extract_single_video(self, url_or_id: str, custom_folder: Optional[str] = None) -> Dict[str, Any]:
        """
        Extrai dados RAG completos de um √∫nico v√≠deo baseado no sistema antigo
        """
        try:
            print(f"\nüé¨ Processando v√≠deo: {url_or_id}")
            
            # Extrair ID do v√≠deo
            video_id = self.extract_video_id(url_or_id)
            if not video_id:
                return {'error': 'ID do v√≠deo inv√°lido', 'input': url_or_id}
            
            print(f"üìπ ID do v√≠deo: {video_id}")
            
            # Timestamp para arquivos
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # Obter metadados
            print("üìä Obtendo metadados...")
            metadata = self.get_video_metadata(video_id)
            
            if 'error' in metadata:
                return {'error': f"Erro ao obter metadados: {metadata['error']}", 'video_id': video_id}
            
            # Criar nome da pasta do v√≠deo (30 caracteres baseado no t√≠tulo)
            video_title = metadata.get('title', f'Video_{video_id}')
            folder_name = self.create_video_folder_name(video_title, video_id)
            
            # Determinar pasta de trabalho
            if custom_folder:
                work_dir = self.storage_dir / custom_folder / folder_name
            else:
                work_dir = self.storage_dir / folder_name
            
            work_dir.mkdir(parents=True, exist_ok=True)
            
            # Criar estrutura de dados dentro da pasta do v√≠deo
            data_dir = work_dir / "youtube_extracted_data"
            data_dir.mkdir(exist_ok=True)
            
            dirs = {
                'transcripts': data_dir / 'transcripts',
                'metadata': data_dir / 'metadata',
                'chunks': data_dir / 'chunks', 
                'rag_content': data_dir / 'rag_content',
                'database': data_dir / 'database'
            }
            
            for directory in dirs.values():
                directory.mkdir(exist_ok=True)
            
            print(f"üìÅ Pasta do v√≠deo: {folder_name}")
            
            # Salvar metadados
            metadata_file = dirs['metadata'] / f"{video_id}_{timestamp}_metadata.json"
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            # Obter transcri√ß√£o
            print("üìù Extraindo transcri√ß√£o...")
            transcript = self.get_transcript_with_fallbacks(video_id)
            
            # Inicializar estrutura de arquivos
            files_created = {
                'transcript_json': None,
                'metadata': str(metadata_file),
                'chunks': None,
                'analysis': None,
                'text': None,
                'chunks_csv': None,
                'database': None,
                'thumbnail': None
            }
            
            statistics = {
                'total_segments': 0,
                'total_chunks': 0,
                'text_length': 0,
                'duration_minutes': metadata.get('duration', 0) / 60
            }
            
            chunks = []
            analysis = {}
            
            if transcript:
                print(f"‚úÖ Transcri√ß√£o encontrada: {len(transcript['segments'])} segmentos")
                
                # Salvar transcri√ß√£o JSON
                transcript_file = dirs['transcripts'] / f"{video_id}_{timestamp}_transcript.json"
                with open(transcript_file, 'w', encoding='utf-8') as f:
                    json.dump(transcript, f, ensure_ascii=False, indent=2)
                files_created['transcript_json'] = str(transcript_file)
                
                # Extrair texto completo
                full_text = transcript['full_text']
                
                # Salvar texto puro
                text_file = dirs['rag_content'] / f"{video_id}_{timestamp}_text.txt"
                with open(text_file, 'w', encoding='utf-8') as f:
                    f.write(full_text)
                files_created['text'] = str(text_file)
                
                # Criar chunks
                print("üîó Criando chunks para RAG...")
                chunks = self.create_chunks(full_text)
                
                # Salvar chunks JSON
                chunks_file = dirs['chunks'] / f"{video_id}_{timestamp}_chunks.json"
                with open(chunks_file, 'w', encoding='utf-8') as f:
                    json.dump(chunks, f, ensure_ascii=False, indent=2)
                files_created['chunks'] = str(chunks_file)
                
                # Salvar chunks CSV
                if PANDAS_AVAILABLE and chunks:
                    chunks_csv = dirs['chunks'] / f"{video_id}_{timestamp}_chunks.csv"
                    chunks_df = pd.DataFrame(chunks)
                    chunks_df.to_csv(chunks_csv, index=False, encoding='utf-8')
                    files_created['chunks_csv'] = str(chunks_csv)
                
                # An√°lise RAG completa
                print("üß† Realizando an√°lise RAG...")
                analysis = self.analyze_content(transcript)
                
                # Salvar an√°lise
                analysis_file = dirs['rag_content'] / f"{video_id}_{timestamp}_analysis.json"
                with open(analysis_file, 'w', encoding='utf-8') as f:
                    json.dump(analysis, f, ensure_ascii=False, indent=2)
                files_created['analysis'] = str(analysis_file)
                
                # Atualizar estat√≠sticas
                statistics.update({
                    'total_segments': len(transcript['segments']),
                    'total_chunks': len(chunks),
                    'text_length': len(full_text)
                })
                
                print(f"üìä Dados extra√≠dos: {len(transcript['segments'])} segmentos, {len(chunks)} chunks, {len(full_text)} caracteres")
            else:
                print("‚ö†Ô∏è Transcri√ß√£o n√£o dispon√≠vel")
                # Criar an√°lise m√≠nima mesmo sem transcri√ß√£o
                analysis = {
                    'statistics': {
                        'total_characters': 0,
                        'total_words': 0,
                        'total_segments': 0,
                        'duration_minutes': metadata.get('duration', 0) / 60
                    },
                    'content_analysis': {
                        'language_detected': 'unknown',
                        'transcript_type': 'unavailable'
                    },
                    'keywords': [],
                    'topics': [],
                    'sentiment': 'neutral'
                }
                
                analysis_file = dirs['rag_content'] / f"{video_id}_{timestamp}_analysis.json"
                with open(analysis_file, 'w', encoding='utf-8') as f:
                    json.dump(analysis, f, ensure_ascii=False, indent=2)
                files_created['analysis'] = str(analysis_file)
            
            # Criar banco de dados
            print("üíæ Criando banco de dados...")
            db_path = dirs['database'] / "youtube_transcripts.db"
            
            conn = sqlite3.connect(str(db_path))
            cursor = conn.cursor()
            
            # Criar estrutura completa do banco
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS video_metadata (
                    video_id TEXT PRIMARY KEY,
                    title TEXT,
                    description TEXT,
                    uploader TEXT,
                    upload_date TEXT,
                    duration INTEGER,
                    view_count INTEGER,
                    like_count INTEGER,
                    extraction_date TEXT,
                    extractor_version TEXT
                )
            ''')
            
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS transcript_segments (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    video_id TEXT,
                    segment_index INTEGER,
                    text TEXT,
                    start_time REAL,
                    duration REAL,
                    end_time REAL,
                    FOREIGN KEY (video_id) REFERENCES video_metadata (video_id)
                )
            ''')
            
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS content_chunks (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    video_id TEXT,
                    chunk_index INTEGER,
                    text TEXT,
                    start_char INTEGER,
                    end_char INTEGER,
                    char_count INTEGER,
                    word_count INTEGER,
                    FOREIGN KEY (video_id) REFERENCES video_metadata (video_id)
                )
            ''')
            
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS content_analysis (
                    video_id TEXT PRIMARY KEY,
                    language_detected TEXT,
                    transcript_type TEXT,
                    total_characters INTEGER,
                    total_words INTEGER,
                    total_segments INTEGER,
                    keywords TEXT,
                    topics TEXT,
                    sentiment TEXT,
                    FOREIGN KEY (video_id) REFERENCES video_metadata (video_id)
                )
            ''')
            
            conn.commit()
            conn.close()
            
            # Salvar dados no banco
            self.save_to_database(str(db_path), video_id, metadata, transcript, chunks, analysis)
            files_created['database'] = str(db_path)
            
            # Baixar thumbnail
            print("üñºÔ∏è Baixando thumbnail...")
            thumbnail_path = self.download_thumbnail(
                video_id, 
                metadata.get('thumbnail', ''), 
                dirs['rag_content']
            )
            if thumbnail_path:
                files_created['thumbnail'] = thumbnail_path
            
            # Criar resumo RAG completo
            rag_summary = {
                'video_id': video_id,
                'video_title': video_title,
                'folder_name': folder_name,
                'extraction_date': timestamp,
                'files_created': files_created,
                'statistics': statistics,
                'metadata': metadata,
                'analysis_summary': analysis
            }
            
            # Salvar resumo
            summary_file = dirs['rag_content'] / f"{video_id}_{timestamp}_summary.json"
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(rag_summary, f, ensure_ascii=False, indent=2)
            
            print(f"‚úÖ V√≠deo processado: '{video_title[:50]}...'")
            print(f"üìÅ Pasta: {folder_name}")
            print(f"üìä Dura√ß√£o: {metadata.get('duration', 0) / 60:.1f} minutos")
            if transcript:
                print(f"üìù Segmentos: {len(transcript['segments'])}")
                print(f"üîó Chunks: {len(chunks)}")
                print(f"üìÑ Caracteres: {len(transcript['full_text'])}")
            
            return {
                'success': True,
                'video_id': video_id,
                'video_title': video_title,
                'folder_name': folder_name,
                'custom_folder': custom_folder,
                'rag_summary': rag_summary,
                'files_created': files_created
            }
            
        except Exception as e:
            logger.error(f"Erro ao processar v√≠deo: {e}")
            return {'error': str(e), 'input': url_or_id}
    
    def extract_playlist(self, playlist_url: str, start_index: int = 1, end_index: int = None) -> Dict[str, Any]:
        """
        Extrai playlist com melhorias:
        - Nome real da playlist
        - Versionamento de pastas
        - Range de v√≠deos (ex: do 3 ao 15)
        - Pastas individuais para cada v√≠deo
        - Controle de mem√≥ria
        """
        try:
            print(f"\nüìã Processando playlist: {playlist_url}")
            
            # Extrair ID da playlist
            playlist_id = self.extract_playlist_id(playlist_url)
            if not playlist_id:
                return {'error': 'ID da playlist inv√°lido', 'input': playlist_url}
            
            print(f"üìã ID da playlist: {playlist_id}")
            
            # Obter informa√ß√µes completas da playlist
            playlist_info = self.get_playlist_info(playlist_id)
            playlist_title = playlist_info.get('title', f'playlist_{playlist_id}')
            video_ids = playlist_info.get('video_ids', [])
            
            if not video_ids:
                return {'error': 'Nenhum v√≠deo encontrado na playlist', 'playlist_id': playlist_id}
            
            print(f"üìã Playlist: '{playlist_title}' ({len(video_ids)} v√≠deos)")
            
            # Criar nome da pasta baseado no t√≠tulo real
            playlist_folder_name = self.create_playlist_folder_name(playlist_title, playlist_id)
            
            # Aplicar versionamento se pasta j√° existir
            versioned_folder_name = self.get_versioned_playlist_folder(playlist_folder_name, self.storage_dir)
            
            # Criar subpasta para a playlist
            playlist_folder = self.storage_dir / versioned_folder_name
            playlist_folder.mkdir(exist_ok=True)
            
            print(f"üìÅ Pasta da playlist: {versioned_folder_name}")
            
            # Aplicar range de v√≠deos se especificado
            if end_index is None:
                end_index = len(video_ids)
            
            # Validar √≠ndices
            start_index = max(1, start_index)
            end_index = min(len(video_ids), end_index)
            
            if start_index > end_index:
                return {'error': f'√çndice inicial ({start_index}) maior que final ({end_index})'}
            
            # Selecionar v√≠deos do range especificado
            selected_videos = video_ids[start_index-1:end_index]
            print(f"üéØ Processando v√≠deos {start_index} at√© {end_index} ({len(selected_videos)} v√≠deos)")
            
            # Salvar informa√ß√µes da playlist
            playlist_metadata = {
                'playlist_info': playlist_info,
                'selected_range': {'start': start_index, 'end': end_index},
                'total_videos': len(video_ids),
                'selected_videos': len(selected_videos),
                'extraction_timestamp': datetime.now().isoformat()
            }
            
            with open(playlist_folder / 'playlist_metadata.json', 'w', encoding='utf-8') as f:
                json.dump(playlist_metadata, f, indent=2, ensure_ascii=False)
            
            # Processar cada v√≠deo selecionado
            results = []
            success_count = 0
            error_count = 0
            
            for i, video_id in enumerate(selected_videos, start_index):
                print(f"\n[{i}/{end_index}] Processando v√≠deo: {video_id}")
                
                # Controle de mem√≥ria antes de cada v√≠deo
                import gc
                
                try:
                    import psutil
                    memory = psutil.virtual_memory()
                    print(f"üíæ Mem√≥ria atual: {memory.percent:.1f}% usada")
                    
                    if memory.percent > 80:
                        print("‚ö†Ô∏è Mem√≥ria alta detectada, for√ßando limpeza...")
                        gc.collect()
                        import time
                        time.sleep(2)  # Dar tempo para limpeza
                        
                        memory = psutil.virtual_memory()
                        if memory.percent > 90:
                            print("üö® MEM√ìRIA CR√çTICA! Pausando processamento...")
                            time.sleep(5)
                            gc.collect()
                except ImportError:
                    print("‚ö†Ô∏è psutil n√£o dispon√≠vel, continuando sem monitoramento de mem√≥ria")
                except Exception:
                    pass  # Se psutil falhar, continuar
                
                try:
                    # Obter metadados primeiro para nome da pasta individual
                    metadata = self.get_video_metadata(video_id)
                    video_title = metadata.get('title', f'Video_{video_id}')
                    video_folder_name = self.create_video_folder_name(video_title, video_id)
                    
                    # Criar pasta individual para o v√≠deo dentro da playlist
                    video_folder = playlist_folder / video_folder_name
                    video_folder.mkdir(exist_ok=True)
                    
                    print(f"üìÅ Pasta do v√≠deo: {playlist_folder.name}/{video_folder_name}")
                    
                    # Extrair o v√≠deo na pasta individual
                    video_url = f"https://www.youtube.com/watch?v={video_id}"
                    
                    # Processar transcri√ß√£o com controle de mem√≥ria
                    transcript = self.get_transcript_with_fallbacks(video_id, video_folder)
                    
                    if transcript:
                        # An√°lise RAG (combinar metadata com transcript para an√°lise)
                        transcript_with_metadata = transcript.copy()
                        transcript_with_metadata.update(metadata)
                        analysis = self.analyze_content(transcript_with_metadata)
                        
                        # Salvar dados na pasta individual do v√≠deo
                        self.save_video_data(video_folder, video_id, metadata, transcript, analysis)
                        
                        result = {
                            'success': True,
                            'video_id': video_id,
                            'title': video_title,
                            'folder': f"{versioned_folder_name}/{video_folder_name}",
                            'segments': len(transcript.get('segments', [])),
                            'source': transcript.get('source', 'unknown')
                        }
                        success_count += 1
                        print(f"‚úÖ [{i}/{end_index}] V√≠deo extra√≠do: {video_folder_name}")
                    else:
                        result = {
                            'success': False,
                            'video_id': video_id,
                            'title': video_title,
                            'error': 'Transcri√ß√£o n√£o dispon√≠vel'
                        }
                        error_count += 1
                        print(f"‚ùå [{i}/{end_index}] Falha na transcri√ß√£o: {video_folder_name}")
                    
                    results.append(result)
                    
                    # Limpeza de mem√≥ria robusta entre v√≠deos para evitar sobrecarga
                    import gc
                    import time
                    
                    print("üßπ Limpando mem√≥ria...")
                    
                    # Liberar vari√°veis grandes
                    transcript = None
                    transcript_with_metadata = None
                    analysis = None
                    metadata = None
                    
                    # For√ßar limpeza do garbage collector
                    gc.collect()
                    gc.collect()  # Duas vezes para garantir
                    
                    # Pausa entre v√≠deos para estabilizar sistema
                    time.sleep(3)
                    
                    try:
                        import psutil
                        memory = psutil.virtual_memory()
                        print(f"üíæ Mem√≥ria ap√≥s limpeza: {memory.percent:.1f}% usada")
                    except ImportError:
                        print("üíæ Limpeza de mem√≥ria conclu√≠da")
                    except:
                        pass
                    
                except Exception as e:
                    error_result = {
                        'success': False,
                        'video_id': video_id,
                        'error': str(e)
                    }
                    results.append(error_result)
                    error_count += 1
                    print(f"‚ùå [{i}/{end_index}] Erro no v√≠deo {video_id}: {e}")
            
            # Criar ZIP da playlist
            zip_path = self.create_playlist_zip(playlist_folder)
            
            final_result = {
                'success': True,
                'playlist_id': playlist_id,
                'playlist_title': playlist_title,
                'folder_name': versioned_folder_name,
                'range_processed': f"{start_index}-{end_index}",
                'total_videos': len(selected_videos),
                'successful_extractions': success_count,
                'failed_extractions': error_count,
                'zip_file': zip_path,
                'results': results
            }
            
            print(f"\nüéâ Playlist processada!")
            print(f"üìÅ Pasta: {versioned_folder_name}")
            print(f"‚úÖ Sucessos: {success_count}/{len(selected_videos)}")
            print(f"‚ùå Falhas: {error_count}/{len(selected_videos)}")
            print(f"üì¶ ZIP: {zip_path}")
            
            return final_result
            
        except Exception as e:
            logger.error(f"Erro ao extrair playlist: {e}")
            return {'error': str(e), 'playlist_url': playlist_url}

    def save_video_data(self, video_folder: Path, video_id: str, metadata: Dict, transcript: Dict, analysis: Dict):
        """
        Salva todos os dados do v√≠deo na pasta individual
        """
        try:
            # Criar pasta youtube_extracted_data igual ao v√≠deo individual
            extracted_folder = video_folder / 'youtube_extracted_data'
            extracted_folder.mkdir(exist_ok=True)
            
            # Criar subpastas organizadas
            chunks_folder = extracted_folder / 'chunks'
            database_folder = extracted_folder / 'database'
            metadata_folder = extracted_folder / 'metadata'
            rag_folder = extracted_folder / 'rag_content'
            transcripts_folder = extracted_folder / 'transcripts'
            
            for folder in [chunks_folder, database_folder, metadata_folder, rag_folder, transcripts_folder]:
                folder.mkdir(exist_ok=True)
            
            # Gerar timestamp
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            base_filename = f"{video_id}_{timestamp}"
            
            # Salvar metadados (formato principal e formato com timestamp)
            with open(video_folder / 'metadata.json', 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            
            metadata_file = metadata_folder / f'{base_filename}_metadata.json'
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            
            # Salvar transcri√ß√£o (formato principal e formato com timestamp)
            transcript_file = video_folder / f'transcript_{video_id}.json'
            with open(transcript_file, 'w', encoding='utf-8') as f:
                json.dump(transcript, f, indent=2, ensure_ascii=False)
                
            transcript_file_ts = transcripts_folder / f'{base_filename}_transcript.json'
            with open(transcript_file_ts, 'w', encoding='utf-8') as f:
                json.dump(transcript, f, indent=2, ensure_ascii=False)
            
            # Salvar an√°lise RAG (ambos locais)
            analysis_file = rag_folder / f'{video_id}_analysis.json'
            with open(analysis_file, 'w', encoding='utf-8') as f:
                json.dump(analysis, f, indent=2, ensure_ascii=False)
                
            analysis_file_ts = rag_folder / f'{base_filename}_analysis.json'
            with open(analysis_file_ts, 'w', encoding='utf-8') as f:
                json.dump(analysis, f, indent=2, ensure_ascii=False)
            
            # Salvar texto puro da transcri√ß√£o
            text_content = self.extract_text_from_segments(transcript.get('segments', []))
            text_file = rag_folder / f'{base_filename}_text.txt'
            with open(text_file, 'w', encoding='utf-8') as f:
                f.write(text_content)
            
            # Criar chunks se poss√≠vel
            try:
                import gc
                print("üîó Iniciando cria√ß√£o de chunks com controle de mem√≥ria...")
                
                # For√ßar limpeza antes de criar chunks
                gc.collect()
                
                chunks = self.create_chunks(text_content)
                if chunks:
                    chunks_file_json = chunks_folder / f'{base_filename}_chunks.json'
                    with open(chunks_file_json, 'w', encoding='utf-8') as f:
                        json.dump(chunks, f, indent=2, ensure_ascii=False)
                        
                    # Salvar chunks em CSV tamb√©m (vers√£o mais leve)
                    chunks_file_csv = chunks_folder / f'{base_filename}_chunks.csv'
                    import csv
                    with open(chunks_file_csv, 'w', newline='', encoding='utf-8') as f:
                        writer = csv.writer(f)
                        writer.writerow(['chunk_id', 'content'])
                        for chunk in chunks:
                            writer.writerow([chunk.get('index', ''), chunk.get('text', '')])
                    
                    print(f"‚úÖ Chunks salvos: {len(chunks)} chunks")
                else:
                    print("‚ö†Ô∏è Nenhum chunk foi criado")
                
                # Limpeza imediata ap√≥s chunks
                chunks = None  # Liberar refer√™ncia
                gc.collect()
                
            except Exception as e:
                print(f"‚ùå Erro ao criar chunks: {e}")
                # For√ßar limpeza em caso de erro
                import gc
                gc.collect()
            
            # Criar banco de dados
            db_path = self.create_database()
            if db_path:
                # Mover banco para pasta do v√≠deo e para database folder
                import shutil
                target_db = video_folder / 'video_database.db'
                shutil.copy2(db_path, target_db)
                
                target_db_ts = database_folder / 'youtube_transcripts.db'
                shutil.copy2(db_path, target_db_ts)
            
            # Baixar thumbnail
            thumbnail_url = metadata.get('thumbnail')
            if thumbnail_url:
                # Thumbnail na pasta principal
                thumbnail_main = video_folder / f'{video_id}_thumbnail.jpg'
                downloaded_thumb = self.download_thumbnail(video_id, thumbnail_url, video_folder)
                
                # Copiar para pasta extracted tamb√©m
                if downloaded_thumb and Path(downloaded_thumb).exists():
                    import shutil
                    shutil.copy2(downloaded_thumb, extracted_folder / f'{video_id}_thumbnail.jpg')
            
            print(f"üíæ Dados salvos em: {video_folder.name}")
            
        except Exception as e:
            print(f"‚ùå Erro ao salvar dados do v√≠deo {video_id}: {e}")
    
    def create_playlist_zip(self, playlist_folder: Path) -> str:
        """
        Cria arquivo ZIP espec√≠fico para uma playlist
        """
        try:
            zip_file = playlist_folder / f"{playlist_folder.name}.zip"
            
            print(f"\nüì¶ Criando ZIP da playlist: {zip_file.name}")
            
            if zip_file.exists():
                zip_file.unlink()
            
            with zipfile.ZipFile(zip_file, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for item in playlist_folder.iterdir():
                    if item.is_dir() and item != zip_file:
                        for file_path in item.rglob('*'):
                            if file_path.is_file():
                                arc_path = file_path.relative_to(playlist_folder)
                                zipf.write(file_path, arc_path)
                    elif item.is_file() and item != zip_file:
                        zipf.write(item, item.name)
            
            zip_size = zip_file.stat().st_size / 1024 / 1024
            print(f"‚úÖ ZIP da playlist criado: {zip_file.name}")
            print(f"üì¶ Tamanho: {zip_size:.1f} MB")
            
            return str(zip_file)
            
        except Exception as e:
            logger.error(f"Erro ao criar ZIP da playlist: {e}")
            return ""
    
    def create_custom_folder_zip(self, folder_path: Path) -> str:
        """
        Cria arquivo ZIP para uma pasta personalizada
        """
        try:
            zip_file = folder_path / f"{folder_path.name}.zip"
            
            print(f"\nüì¶ Criando ZIP da pasta: {zip_file.name}")
            
            if zip_file.exists():
                zip_file.unlink()
            
            with zipfile.ZipFile(zip_file, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for item in folder_path.iterdir():
                    if item.is_dir() and item != zip_file:
                        for file_path in item.rglob('*'):
                            if file_path.is_file():
                                arc_path = file_path.relative_to(folder_path)
                                zipf.write(file_path, arc_path)
                    elif item.is_file() and item != zip_file:
                        zipf.write(item, item.name)
            
            zip_size = zip_file.stat().st_size / 1024 / 1024
            print(f"‚úÖ ZIP da pasta criado: {zip_file.name}")
            print(f"üì¶ Tamanho: {zip_size:.1f} MB")
            
            return str(zip_file)
            
        except Exception as e:
            logger.error(f"Erro ao criar ZIP da pasta: {e}")
            return ""
    
    def list_extracted_videos(self) -> List[Dict[str, Any]]:
        """
        Lista todos os v√≠deos extra√≠dos
        """
        videos = []
        
        try:
            for item in self.storage_dir.rglob('*_summary.json'):
                try:
                    with open(item, 'r', encoding='utf-8') as f:
                        summary = json.load(f)
                        summary['file_path'] = str(item)
                        videos.append(summary)
                except:
                    continue
            
            return sorted(videos, key=lambda x: x.get('extraction_date', ''), reverse=True)
            
        except Exception as e:
            logger.error(f"Erro ao listar v√≠deos: {e}")
            return []

def main():
    """
    SISTEMA RAG YOUTUBE - VERS√ÉO FINAL COM SOLU√á√ÉO PARA BLOQUEIO IP
    
    üéØ INSTALA√á√ÉO DE BIBLIOTECAS PARA TRANSCRI√á√ÉO LOCAL:
    
    Para m√°xima qualidade (Whisper):
    pip install openai-whisper
    
    Para fallback (SpeechRecognition):
    pip install SpeechRecognition pydub
    
    Para Windows (bibliotecas sistema):
    pip install pyaudio
    
    üîß RECURSOS IMPLEMENTADOS:
    - ‚úÖ Proxy/Tor para contornar bloqueio IP
    - ‚úÖ Download de √°udio + transcri√ß√£o local (SOLU√á√ÉO DEFINITIVA)
    - ‚úÖ M√∫ltiplas estrat√©gias de fallback
    - ‚úÖ Pastas com 30 caracteres
    - ‚úÖ Subpastas para playlists
    - ‚úÖ Keywords inteligentes
    - ‚úÖ Sistema RAG completo
    """
    parser = argparse.ArgumentParser(
        description='üé¨ Extrator RAG Completo de V√≠deos do YouTube',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemplos de uso:

  # Extrair um v√≠deo
  python youtube_rag_extractor_final.py --url "https://www.youtube.com/watch?v=VIDEO_ID"
  
  # Extrair v√≠deo em pasta personalizada
  python youtube_rag_extractor_final.py --url "VIDEO_URL" --folder "meus_videos"
  
  # Extrair com proxy HTTP
  python youtube_rag_extractor_final.py --url "VIDEO_URL" --proxy "http://proxy.com:8080"
  
  # Extrair com proxy SOCKS5/Tor
  python youtube_rag_extractor_final.py --url "VIDEO_URL" --proxy "socks5://127.0.0.1:9050"
  
  # Extrair usando Tor (atalho)
  python youtube_rag_extractor_final.py --url "VIDEO_URL" --tor
  
  # Extrair playlist completa (cria subpasta automaticamente)
  python youtube_rag_extractor_final.py --playlist "https://www.youtube.com/playlist?list=PLAYLIST_ID"
  
  # Listar v√≠deos extra√≠dos
  python youtube_rag_extractor_final.py --list
  
  # Criar ZIP de pasta espec√≠fica
  python youtube_rag_extractor_final.py --zip-folder "nome_da_pasta"
"""
    )
    
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument('--url', '-u', help='URL do v√≠deo do YouTube')
    group.add_argument('--playlist', '-p', help='URL da playlist do YouTube')
    group.add_argument('--list', '-l', action='store_true', help='Listar v√≠deos extra√≠dos')
    group.add_argument('--zip-folder', '-z', help='Criar ZIP de uma pasta espec√≠fica')
    
    parser.add_argument('--storage', '-s', default='storage', help='Diret√≥rio de armazenamento (padr√£o: storage)')
    parser.add_argument('--folder', '-f', help='Pasta personalizada para v√≠deo individual')
    parser.add_argument('--proxy', help='Proxy: http://host:port ou socks5://host:port')
    parser.add_argument('--tor', action='store_true', help='Usar Tor (equivale a --proxy socks5://127.0.0.1:9050)')
    
    # Novos argumentos para range de playlist
    parser.add_argument('--start', type=int, default=1, help='√çndice inicial da playlist (padr√£o: 1)')
    parser.add_argument('--end', type=int, help='√çndice final da playlist (padr√£o: todos os v√≠deos)')
    
    args = parser.parse_args()
    
    # Criar extrator
    extractor = YouTubeRAGExtractor(args.storage, proxy=args.proxy, use_tor=args.tor)
    
    # Op√ß√£o de pasta personalizada via input se n√£o foi especificada via argumento
    if args.url and not args.folder:
        try:
            custom_folder = input("\nüóÇÔ∏è  Deseja usar uma pasta personalizada? (Enter para padr√£o): ").strip()
            if custom_folder:
                args.folder = custom_folder
                print(f"üìÅ Pasta personalizada: {custom_folder}")
        except (KeyboardInterrupt, EOFError):
            print("\n‚è≠Ô∏è  Usando pasta padr√£o")
    
    try:
        if args.url:
            # Extrair v√≠deo √∫nico
            result = extractor.extract_single_video(args.url, args.folder)
            
            if result.get('success'):
                print(f"\nüéâ Extra√ß√£o RAG conclu√≠da com sucesso!")
                
                # Criar ZIP da pasta personalizada se especificada
                if args.folder:
                    folder_path = extractor.storage_dir / args.folder
                    if folder_path.exists():
                        zip_path = extractor.create_custom_folder_zip(folder_path)
                        if zip_path:
                            print(f"üì¶ ZIP da pasta criado: {zip_path}")
            else:
                print(f"\n‚ùå Erro na extra√ß√£o: {result.get('error')}")
                sys.exit(1)
        
        elif args.playlist:
            # Extrair playlist com range opcional
            if args.start > 1 or args.end:
                print(f"üéØ Processando playlist do v√≠deo {args.start} at√© {args.end}")
            
            result = extractor.extract_playlist(args.playlist, args.start, args.end)
            
            if result.get('success'):
                print(f"\nüéâ Playlist extra√≠da com sucesso!")
                print(f"üìä {result['successful_extractions']}/{result['total_videos']} v√≠deos processados")
                print(f"üìÅ Pasta da playlist: {result.get('folder_name', result.get('playlist_folder', 'N/A'))}")
                if result.get('zip_file'):
                    print(f"üì¶ ZIP da playlist: {result['zip_file']}")
            else:
                print(f"\n‚ùå Erro na extra√ß√£o da playlist: {result.get('error')}")
                sys.exit(1)
        
        elif args.list:
            # Listar v√≠deos
            videos = extractor.list_extracted_videos()
            
            if videos:
                print(f"\nüìπ V√≠deos extra√≠dos ({len(videos)} total):")
                print("=" * 80)
                
                for i, video in enumerate(videos, 1):
                    metadata = video.get('metadata', {})
                    stats = video.get('statistics', {})
                    duration_min = stats.get('duration_minutes', 0)
                    segments = stats.get('total_segments', 0)
                    chunks = stats.get('total_chunks', 0)
                    title = metadata.get('title', 'T√≠tulo n√£o encontrado')
                    
                    print(f"{i:2d}. {title[:50]}...")
                    print(f"    üìÅ {Path(video['file_path']).parent.name}")
                    print(f"    ‚è±Ô∏è {duration_min:.1f}min | üìù {segments} segmentos | üîó {chunks} chunks")
                    print(f"    üìÖ {video.get('extraction_date', '')}")
                    print()
            else:
                print("\nüìπ Nenhum v√≠deo extra√≠do ainda.")
        
        elif args.zip_folder:
            # Criar ZIP de pasta espec√≠fica
            folder_path = extractor.storage_dir / args.zip_folder
            
            if not folder_path.exists():
                print(f"\n‚ùå Pasta n√£o encontrada: {args.zip_folder}")
                sys.exit(1)
            
            zip_path = extractor.create_custom_folder_zip(folder_path)
            
            if zip_path:
                print(f"\n‚úÖ ZIP criado: {zip_path}")
            else:
                print(f"\n‚ùå Erro ao criar ZIP")
                sys.exit(1)
    
    except KeyboardInterrupt:
        print(f"\n\n‚ö†Ô∏è Opera√ß√£o cancelada pelo usu√°rio")
        sys.exit(1)
    except Exception as e:
        logger.error(f"Erro inesperado: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
